import uuid
import requests
from mydemo.pywright.chrome_util import ChromeBrowser
from mydemo.utils.content_type_util import infer_file_type,infer_file_name
from mydemo.utils.download import save_bytes
import os
from urllib.parse import urlparse, urljoin


### æµ‹è¯•ä¸‹è½½

# è®¾ç½®ä¸‹è½½ç›®å½•ï¼ˆç»å¯¹è·¯å¾„ï¼‰
download_dir = os.path.abspath("/Users/jiaxiaopeng/opt/")
os.makedirs(download_dir, exist_ok=True)

def handle_route(route):
    response = route.fetch()
    content = response.body()
    print(response.url)
    suggested = response.headers.get("content-disposition", "")
    print(suggested)
    name = infer_file_name(response.url, "mp3")
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(path := os.path.join(download_dir, name), "wb") as f:
        f.write(content)
        print(path)
    route.continue_()  # æˆ– abort() å¦‚æœä¸æƒ³åŠ è½½åˆ°é¡µé¢

def download1():
    cb = ChromeBrowser()
    page = cb.get_new_page()
    # æ‹¦æˆª jpg/png/mp3 è¯·æ±‚
    page.route("**/*.{jpg,jpeg,png,mp3}", handle_route)

    page.goto("https://www.21voa.com/special_english/wilbur-and-orville-wright-the-first-airplane-93397.html")
    page.wait_for_load_state("networkidle")

    # mp3_src = page.eval_on_selector("xpath=//*[@id='mp3']", "el => el.href")
    # print(f"mp3_src: {mp3_src}")
    page.click("xpath=//*[@id='mp3']")



def download2():
    cb = ChromeBrowser()
    page = cb.get_new_page()
    page.goto("https://www.21voa.com/special_english/wilbur-and-orville-wright-the-first-airplane-93397.html")
    page.wait_for_load_state("networkidle")
    with page.expect_download() as download_info:
        page.click("xpath=//*[@id='mp3']")

    download = download_info.value
    # # # ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
    save_path = os.path.join(download_dir, download.suggested_filename)
    download.save_as(save_path)

    print(f"æ–‡ä»¶å·²ä¸‹è½½å¹¶ä¿å­˜åˆ°: {save_path}")

# ç›‘å¬æ–°é¡µé¢ï¼ˆç”¨äºåç»­æ“ä½œï¼‰
# new_page = None
# def on_page(page):
#     global new_page
#     new_page = page
#     print("ç›‘å¬é¡µé¢åˆ›å»º:", page.url)
# # æ³¨å†Œ
# cb._context.on("page", on_page)

def handle_download(download, path):
    file_path = path + download.suggested_filename
    print(f"è§¦å‘ä¸‹è½½å‡†å¤‡ä¿å­˜: {file_path}")
    download.save_as(file_path)
    print(f"æ–‡ä»¶å·²ä¸‹è½½å¹¶ä¿å­˜åˆ°: {file_path}")

def handle_response(response):
    # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬è¦ä¸‹è½½çš„å›¾ç‰‡ URL
    print(f"url: {response.url}")
    if response.url is not None:
        content_type = response.headers.get("content-type", "")
        print(f"content_type: {content_type}")
        # å›¾ç‰‡å¯ä¸‹è½½
        if "image/" in content_type:
            try:
                image_data = response.body()
                filename = infer_file_name(response.url, content_type)
                save_path = '/Users/jiaxiaopeng/Downloads/' + filename
                # ä¿å­˜
                save_bytes(save_path, image_data)
            except Exception as e:
                print(f"è¯»å–å“åº”ä½“å¤±è´¥: {e}")




# page.on("download", lambda download: handle_download(download, download_dir))?

# page.on("response", handle_response)
# page.goto("https://haowallpaper.com/homeViewLook/17854958797835648")
# page.goto("https://www.meilisearch.com/docs/learn/self_hosted/getting_started_with_self_hosted_meilisearch")
# Playwright ä¼šè‡ªåŠ¨ç­‰å¾…å…ƒç´ å‡ºç°å¹¶å¯äº¤äº’
button_xpath = '//*[@id="content"]/span[11]/a'  # ğŸ‘ˆ æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ XPath
# try:
#     # ç­‰å¾…å…ƒç´ å‡ºç°åœ¨ DOM ä¸­ï¼ˆä¸ä¸€å®šå¯è§ï¼‰
#     element = page.wait_for_selector(button_xpath, state="attached", timeout=10000)
#
#     # æ»šåŠ¨åˆ°è¯¥å…ƒç´ ï¼ˆå¦‚æœéœ€è¦ï¼‰
#     element.scroll_into_view_if_needed(timeout=5000)
#
#     # å†ç­‰å¾…å®ƒå˜ä¸ºå¯è§ï¼ˆä¾‹å¦‚ï¼šä¸è¢«é®æŒ¡ã€opacity > 0 ç­‰ï¼‰
#     element.wait_for_element_state("visible", timeout=10000)
#
#     print("âœ… æŒ‰é’®å·²æ‰¾åˆ°å¹¶å¯è§ï¼Œå‡†å¤‡ç‚¹å‡»...")
#     element.click()
#
#     print(element.as_element())
#
# except TimeoutError:
#     print("âŒ è¶…æ—¶ï¼šæœªæ‰¾åˆ°æŒ‰é’®æˆ–æŒ‰é’®ä¸å¯è§")

# href = page.get_attribute(button_xpath, "href")
# print(href)
# full_url = urljoin(page.url, href)
# print(full_url)
# cookies = {c["name"]: c["value"] for c in cb._context.cookies()}
# cb._context.storage_state(path="cookies.json")
# resp = requests.get(full_url, cookies=cookies, headers={"Referer": page.url})
# with open("/Users/jiaxiaopeng/Downloads/movies.json" , "wb") as f:
#     f.write(resp.content)
# print("âœ… é€šè¿‡ requests ä¸‹è½½æˆåŠŸ")

# page.wait_for_timeout(1000)  # ç»™ä¸€ç‚¹æ—¶é—´è®©æ–°é¡µé¢è§¦å‘
# page.click(button_xpath)
# with page.expect_download(timeout=10000) as download_info:  # ğŸ‘ˆ å…³é”®ï¼šç›‘å¬ä¸‹è½½
#     page.click(button_xpath)

# if new_page is None:
#         print("æœªæ£€æµ‹åˆ°æ–°é¡µé¢æ‰“å¼€ï¼")
#         # åœ¨å½“å‰é¡µä¸‹è½½
#         with page.expect_download() as download_info:
#             page.click(button_xpath)
# else:
#     # ç­‰å¾…æ–°é¡µé¢åŠ è½½ï¼ˆå¯é€‰ï¼‰
#     new_page.wait_for_load_state("domcontentloaded")
#     # å‡è®¾æ–°é¡µé¢æœ‰ä¸€ä¸ªâ€œç¡®è®¤ä¸‹è½½â€æŒ‰é’®ï¼ˆæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
#     confirm_button_xpath = '//button[contains(text(), "ç¡®è®¤ä¸‹è½½")]'
#     # å°è¯•æŸ¥æ‰¾ç¡®è®¤æŒ‰é’®ï¼Œå¦‚æœå­˜åœ¨å°±ç‚¹å‡»ï¼›å¦åˆ™è®¤ä¸ºä¼šè‡ªåŠ¨ä¸‹è½½
#     with new_page.expect_download(timeout=30000) as download_info:
#         if new_page.is_visible(confirm_button_xpath):
#             new_page.click(confirm_button_xpath)
#         else:
#             # å¦‚æœæ²¡æœ‰ç¡®è®¤æŒ‰é’®ï¼Œå¯èƒ½å·²è‡ªåŠ¨å¼€å§‹ä¸‹è½½
#             # Playwright ä¼šè‡ªåŠ¨æ•è·åç»­çš„ä¸‹è½½
#             pass


# è·å–ä¸‹è½½å¯¹è±¡
#


# if new_page is not None:
#     # å…³é—­æ–°é¡µé¢
#     new_page.close()
# å…³é—­å½“å‰é¡µ
# page.close()


if __name__ == "__main__":
    # handle_download(download=download, path=save_path)
    download1()